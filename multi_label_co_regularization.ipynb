{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multi_label_co_regularization.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1DqdiDxC3WNUnNTLDrehtui6lmrXJ2E8O","authorship_tag":"ABX9TyNBTbJW0g5k41f0Zi44ErwZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xVF8Rvy9K8XW","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import sys\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import scipy.io as sio\n","\n","import torch.nn.functional as F\n","import random\n","import math\n","\n","import torch.utils.model_zoo as model_zoo\n","from torch.nn import Parameter\n","\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import ImageFolder\n","\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-16B2pDNhlm","colab_type":"text"},"source":["# Loss"]},{"cell_type":"markdown","metadata":{"id":"j4AYlBGzLwEm","colab_type":"text"},"source":["### Loss BCE"]},{"cell_type":"code","metadata":{"id":"Ash6WCyhLdHI","colab_type":"code","colab":{}},"source":["class BCE_sigmoid(nn.Module):\n","    def __init__(self, size_average = False):\n","        super(BCE_sigmoid, self).__init__()\n","        self.size_average = size_average\n","\n","    def forward(self, x, labels):\n","        N = x.size(0)  # batch size\n","        mask1 = labels.eq(0) \n","\n","        mask = 1 - mask1.float()\n","\n","        target = labels.gt(0) \n","        target = target.float()\n","\n","        # This loss combines a Sigmoid layer and the BCELoss in one single class\n","        loss = F.binary_cross_entropy_with_logits(x, target, size_average = False)\n","\n","        if self.size_average:\n","            loss = loss/N\n","\n","        return loss\n","\n","class BCE_sigmoid_negtive_bias_all(nn.Module):\n","    def __init__(self, size_average = False, AU_num = 12, AU_idx = [0,1,2,3,4,5,6,7,8,9,10,11], database = 0):\n","        super(BCE_sigmoid_negtive_bias_all, self).__init__()\n","        self.size_average = size_average\n","        self.AU_num = AU_num\n","        self.AU_idx = AU_idx\n","        self.boundary = 1\n","\n","        # balance weights for different databases\n","        if database == 0:\n","            self.weight = torch.tensor([0.3, 0.2, 0.3, 0.2, 0.2, 0.2, 0.2, 0.3, 0.2, 0.5, 0.2, 0.1])\n","            self.weight = self.weight.cuda()\n","        elif database == 1:\n","            self.weight = [0.3, 0.3, 0.5, 0.3, 0.3, 0.5, 0.3, 0.5, 0.3, 0.3, 0.3, 0.3]\n","\n","        self.balance_a = []\n","        for i in range(0,self.AU_num):\n","            self.balance_a.append(self.weight[self.AU_idx[i]])\n","\n","    def forward(self, x, labels):\n","        N = x.size(0)\n","\n","        mask1 = labels.eq(0)\n","        mask = 1 - mask1.float()\n","\n","        # selective learning balance\n","        for i in range(0, self.AU_num):\n","            temp = labels[:,i]\n","            zero_num = torch.sum(temp.eq(0))\n","            pos_num = torch.sum(temp.eq(1))\n","            neg_num = torch.sum(temp.eq(-1))\n","            zero_num = zero_num.float()\n","            pos_num = pos_num.float()\n","            neg_num = neg_num.float()\n","            half_num = (N - zero_num)*self.balance_a[i]\n","\n","            if (pos_num.item() <  half_num.item()):\n","                idx = torch.nonzero(temp.eq(-1))\n","\n","                sample_num = int(neg_num.data - math.ceil(half_num.data))\n","\n","                if sample_num < 1:\n","                    continue\n","\n","                zero_idx = random.sample(idx, sample_num)\n","                for j in range(0, len(zero_idx)):\n","                    mask[int(zero_idx[j].data), i] = 0\n","\n","                # postive under-representation\n","                if pos_num.data[0] != 0:\n","                    ratio = half_num/pos_num\n","                    if ratio.data[0] > self.boundary:\n","                        ratio = self.boundary\n","\n","                    idx = torch.nonzero(temp.eq(1))\n","                    for j in range(0, len(idx)):\n","                        mask[int(idx[j].data), i] = ratio\n","\n","        target = labels.gt(0)\n","        target = target.float()\n","\n","        loss = F.binary_cross_entropy_with_logits(x, target, size_average = False)\n","\n","        if self.size_average:\n","            loss = loss/N\n","\n","        return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDtoSyfML8rC","colab_type":"text"},"source":["### Loss multi view final"]},{"cell_type":"code","metadata":{"id":"OoVbUmBtL8AP","colab_type":"code","colab":{}},"source":["class MultiView_all_loss(nn.Module):\n","    def __init__(self, AU_num = 12, AU_idx = [0,1,2,3,4,5,6,7,8,9,10,11], fusion_mode = 0,\n","                 use_web = 0, database = 0, lambda_co_regularization = 400, lambda_multi_view = 100):\n","\n","        super(MultiView_all_loss, self).__init__()\n","\n","        self.lossfunc = BCE_sigmoid_negtive_bias_all(size_average=True, AU_num = AU_num, AU_idx = AU_idx, database = database)\n","\n","        self.BCE = nn.BCELoss()\n","        self.sigmoid = nn.Sigmoid()\n","        self.log_sigmoid = nn.LogSigmoid()\n","\n","        self.AU_num = AU_num\n","        self.AU_idx = AU_idx\n","        self.lambda_co_regularization = lambda_co_regularization\n","        self.lambda_multi_view = lambda_multi_view\n","        self.eps = 0.001\n","\n","        self.fusion_mode = fusion_mode\n","        self.use_web = use_web\n","\n","    def forward(self, gt, pre, pre1, pre2, weight1, bias1, weight2, bias2, feat1, feat2, flag):\n","        # flag is used for denoting whether the image is labeled \n","        # flag == 1 means the image is labeled\n","        N = gt.size(0)\n","\n","        mask = flag.eq(1)\n","        mask = mask.cuda()\n","\n","        pre_label1 = torch.masked_select(pre1, mask) \n","        pre_label1 = pre_label1.view(-1, self.AU_num)\n","\n","        pre_label2 = torch.masked_select(pre2, mask)\n","        pre_label2 = pre_label2.view(-1, self.AU_num)\n","\n","        pre_label = torch.masked_select(pre, mask)\n","        pre_label = pre_label.view(-1, self.AU_num)\n","\n","        gt = torch.masked_select(gt, mask)\n","        gt = gt.view(-1, self.AU_num)\n","\n","        if bool(gt.numel()):\n","            loss_pred = self.lossfunc(pre_label, gt)\n","            loss_pred1 = self.lossfunc(pre_label1, gt)\n","            loss_pred2 = self.lossfunc(pre_label2, gt)\n","        else:\n","            loss_pred = Variable(torch.FloatTensor([0])).cuda()\n","            loss_pred1 = Variable(torch.FloatTensor([0])).cuda()\n","            loss_pred2 = Variable(torch.FloatTensor([0])).cuda()\n","\n","        if self.fusion_mode == 0:\n","            loss_BCE = (loss_pred1 + loss_pred2)/2\n","        else:\n","            loss_BCE = loss_pred + (loss_pred1 + loss_pred2)/2\n","\n","        ############### loss multi-view ###############\n","        loss_multi_view = torch.FloatTensor([0])\n","        loss_multi_view = loss_multi_view.cuda()\n","\n","        bias1 = bias1.view(self.AU_num, -1)\n","        feat1 = torch.cat((weight1, bias1), 1) \n","        bias2 = bias2.view(self.AU_num, -1)\n","        feat2 = torch.cat((weight2, bias2), 1) \n","\n","        tmp = torch.norm(feat1, 2, 1)\n","        feat_norm1 = feat1 / tmp.view(self.AU_num, -1)\n","        tmp = torch.norm(feat2, 2, 1)\n","        feat_norm2 = feat2 / tmp.view(self.AU_num, -1)\n","\n","        x = feat_norm1 * feat_norm2 \n","        x = torch.sum(x, 1)\n","        loss_weight_orth = torch.mean(torch.abs(x))\n","        loss_multi_view = loss_multi_view + loss_weight_orth\n","\n","        loss_multi_view = loss_multi_view*self.lambda_multi_view\n","        ############ end loss multi-view ############\n","\n","        ############### J-S divergence ###############\n","        loss_similar = torch.FloatTensor([0])\n","        loss_similar = loss_similar.cuda()\n","\n","        # use_web: 0 only test images/ 1 training with unlabeled images\n","        if self.use_web != 0:\n","            p1 = self.sigmoid(pre1)\n","            log_p1 = self.log_sigmoid(pre1)\n","            p2 = self.sigmoid(pre2)\n","            log_p2 = self.log_sigmoid(pre2)\n","            p = (p1+p2)/2\n","\n","            mask_idx = torch.ge(p1, -1)\n","            idx1 = torch.le(p1, 1 - self.eps) \n","            idx2 = torch.ge(p1, self.eps)\n","            idx = idx1&idx2&mask_idx\n","            tmp_p1 = 1-p1[idx] + self.eps\n","            Hp1 = torch.mean(-(p1[idx]*log_p1[idx] + tmp_p1*torch.log(tmp_p1)))\n","\n","            idx1 = torch.le(p2, 1 - self.eps)\n","            idx2 = torch.ge(p2, self.eps)\n","            idx = idx1&idx2&mask_idx\n","            tmp_p2 = 1-p2[idx] + self.eps\n","            Hp2 = torch.mean(-(p2[idx]*log_p2[idx] + tmp_p2*torch.log(tmp_p2)))\n","\n","            idx1 = torch.le(p, 1 - self.eps)\n","            idx2 = torch.ge(p, self.eps)\n","            idx = idx1&idx2&mask_idx\n","            tmp_p11 = p[idx] + self.eps\n","            tmp_p22 = 1-p[idx] + self.eps\n","            H1 = torch.mean(-(tmp_p11*torch.log(tmp_p11) + (tmp_p22)*torch.log(tmp_p22)))\n","\n","            H2 = (Hp1 + Hp2)/2\n","\n","            loss_web = torch.abs(H1 - H2)\n","            loss_similar = loss_web\n","\n","        loss_similar = loss_similar * self.lambda_co_regularization # Lcr\n","        ################# end J-S divergence #################\n","        # print(\"loss_BCE %4.2f, loss_multi_view %4.2f, loss_similar %4.2f\" % (loss_BCE, loss_multi_view, loss_similar))\n","        loss = loss_BCE + loss_multi_view + loss_similar\n","\n","        return loss, loss_pred, loss_pred1, loss_pred2, loss_multi_view, loss_similar"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7UPZ6HCNbYF","colab_type":"text"},"source":["# Net"]},{"cell_type":"markdown","metadata":{"id":"lPPkDO4CNR5G","colab_type":"text"},"source":["### ResNet"]},{"cell_type":"code","metadata":{"id":"OdH2Ni_iNaHm","colab_type":"code","colab":{}},"source":["__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n","           'resnet152']\n","\n","model_urls = {\n","    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n","    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n","    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n","    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n","    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n","} # download pre-trained network\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes) \n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class Bottleneck(nn.Module): \n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=1000, ave_size=7, num_output = 1):\n","        self.inplanes = 64\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","\n","        self.avgpool = nn.AvgPool2d(ave_size, stride=1)\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","        self.num_output = num_output\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        conv1 = self.maxpool(x)\n","\n","        conv2 = self.layer1(conv1)\n","        conv3 = self.layer2(conv2)  # B*128*28*28\n","        conv4 = self.layer3(conv3)  # B*256*14*14\n","        conv5 = self.layer4(conv4)  # B*512*7*7\n","\n","        x = self.avgpool(conv5)\n","        feat = x.view(x.size(0), -1)\n","        x = self.fc(feat)\n","\n","        if self.num_output == 1:\n","            return  x, conv1\n","        elif self.num_output == 2:\n","            return x, conv2\n","        elif self.num_output == 3:\n","            return x, conv3\n","        elif self.num_output == 4:\n","            return x, conv4\n","        elif self.num_output == 5:\n","            return x, conv5\n","        elif self.num_output == 6:\n","            return x, feat\n","        elif self.num_output == 36:\n","            return x, conv3, feat\n","        else:\n","            return x\n","\n","def resnet18(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-18 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n","    return model\n","\n","def resnet34(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-34 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n","    return model\n","\n","def resnet50(**kwargs):\n","    \"\"\"Constructs a ResNet-50 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n","    return model\n","\n","def resnet101(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-101 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n","    return model\n","\n","def resnet152(pretrained=False, **kwargs):\n","    \"\"\"Constructs a ResNet-152 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n","    if pretrained:\n","        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lX0ujs-zNz7B","colab_type":"text"},"source":["### ResNet GCN"]},{"cell_type":"code","metadata":{"id":"CvUouICDN7V3","colab_type":"code","colab":{}},"source":["def gen_A_cov(AU_num, AU_idx, database):\n","    self_AU_num = AU_num\n","    self_AU_idx = AU_idx\n","\n","    path = '/content/drive/My Drive/dl_project/net/'\n","\n","    if database == 0:\n","        path = path + 'relation_EmotioNet.mat'\n","        # parameters Wij of AU classifiers for both views\n","        # used as nodes of GCN\n","        # first pre-train the feature generators and classifiers\n","        # use the weights of the pre-trained classifiers as the initial input of GCN\n","        self_relation_all = sio.loadmat(path)['relation']\n","    elif database == 1:\n","        path = path + 'relation_BP4D.mat'\n","        self_relation_all = sio.loadmat(path)['relation']\n","\n","    self_AU_relation = torch.zeros(self_AU_num, self_AU_num)\n","    for i in range(0, AU_num):\n","        for j in range(0, AU_num):\n","            self_AU_relation[i, j] = self_relation_all[self_AU_idx[i], self_AU_idx[j]]\n","\n","    _adj = torch.abs(self_AU_relation)\n","\n","    return _adj\n","\n","def gen_adj(A):  # get adjacency matrix\n","    D = torch.pow(A.sum(1).float(), -0.5)\n","    D = torch.diag(D)\n","    adj = torch.matmul(torch.matmul(A, D).t(), D)\n","    return adj\n","\n","class GraphConvolution(nn.Module):\n","\n","    def __init__(self, in_features, out_features, bias=False):\n","        super(GraphConvolution, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = Parameter(torch.Tensor(in_features, out_features))\n","        if bias:\n","            self.bias = Parameter(torch.Tensor(1, 1, out_features))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1. / math.sqrt(self.weight.size(1))\n","        self.weight.data.uniform_(-stdv, stdv)\n","        if self.bias is not None:\n","            self.bias.data.uniform_(-stdv, stdv)\n","\n","    def forward(self, input, adj):\n","        support = torch.matmul(input, self.weight)\n","        support = support.cuda()\n","        adj = adj.cuda()\n","        output = torch.matmul(adj, support)\n","\n","        if self.bias is not None:\n","            return output + self.bias\n","        else:\n","            return output\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + ' (' \\\n","               + str(self.in_features) + ' -> ' \\\n","               + str(self.out_features) + ')'\n","\n","class GCN_layer(nn.Module):\n","    def __init__(self, num_classes = 12, AU_idx = [0,1,2,3,4,5,6,7,8,9,10,11], in_channel = 513, database = 0, weight_relation = 6):\n","        super(GCN_layer, self).__init__()\n","\n","        self.num_classes = num_classes\n","        self.AU_idx = AU_idx\n","        self.database = database\n","        self.weight_relation = weight_relation\n","\n","        self.gc1 = GraphConvolution(in_channel, 513)\n","        self.gc2 = GraphConvolution(513, 513)\n","        self.relu = nn.LeakyReLU(0.2)\n","\n","        _adj = gen_A_cov(num_classes, AU_idx, database)\n","\n","        self.A = _adj\n","\n","    def forward(self, x):\n","\n","        x = x.t() # [12,513]\n","        adj = gen_adj(self.A).detach()\n","        x = self.gc1(x, adj)\n","        x = self.relu(x)\n","        x = self.gc2(x, adj)\n","\n","        x = x.transpose(0, 1)\n","        return x\n","\n","    def get_config_optim(self, lr, lrp):\n","        return [\n","                {'params': self.features.parameters(), 'lr': lr * lrp},\n","                {'params': self.gc1.parameters(), 'lr': lr},\n","                {'params': self.gc2.parameters(), 'lr': lr},\n","                ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ao-5YHrfOJV4","colab_type":"text"},"source":["### ResNet multi view"]},{"cell_type":"code","metadata":{"id":"C5hBOk9gOU9_","colab_type":"code","colab":{}},"source":["class ResNet_GCN_two_views(nn.Module):\n","    def __init__(self, AU_num = 12, AU_idx = [0,1,2,3,4,5,6,7,8,9,10,11], output = 1, fusion_mode = 0, database = 0):\n","        super(ResNet_GCN_two_views, self).__init__()                \n","\n","        self.net1 = resnet34(num_classes=AU_num, num_output=6)\n","        self.net2 = resnet34(num_classes=AU_num, num_output=6)\n","\n","        self.AU_num = AU_num\n","        self.AU_idx = AU_idx\n","        self.fusion_mode = fusion_mode\n","        self.output = output\n","        self.scale = 1\n","\n","        # Different methods to fuse the features of the two views.\n","        # For fair comparasion, we choose to not fuse the two features.\n","        ### fusion_mode: 0 no fusion / 1 concate / 2 mean / 3 concate two layer\n","        if self.fusion_mode == 0 or self.fusion_mode == 1:\n","            self.fc = nn.Linear(1024, AU_num) \n","        elif self.fusion_mode == 2:\n","            self.fc = nn.Linear(512, AU_num)\n","        elif self.fusion_mode == 3:\n","            self.fc = nn.Sequential(\n","                nn.Linear(1024, 512),\n","                nn.ELU(),\n","                nn.Linear(512, AU_num)\n","            )\n","\n","        self.Is_begin_weight = True\n","        self.begin_weight1 = None\n","        self.begin_weight2 = None\n","        self.relation = GCN_layer(num_classes = AU_num, AU_idx = self.AU_idx, in_channel = 513, database = database);\n","        # obtain AU relationship by GCN\n","\n","    def forward(self, data):\n","        N = data.size(0) # data = [batch size, 3, 224, 224]\n","\n","        output1, feat1 = self.net1(data)\n","        output2, feat2 = self.net2(data)\n","\n","        weight1 = self.net1.fc.weight\n","        bias1 = self.net1.fc.bias\n","        weight2 = self.net2.fc.weight\n","        bias2 = self.net2.fc.bias\n","\n","        bias1 = bias1.view(self.AU_num, -1)\n","        weight_norm1 = torch.cat((weight1, bias1), 1)\n","        bias2 = bias2.view(self.AU_num, -1)\n","        weight_norm2 = torch.cat((weight2, bias2), 1)\n","\n","        feat_norm1 = feat1\n","        feat_norm2 = feat2\n","\n","        # We need the pre-trained weights as the initialization of GCN. \n","        # These values are used for controlling the initialization.\n","        if self.Is_begin_weight: \n","            self.begin_weight1 = weight_norm1\n","            self.begin_weight2 = weight_norm2\n","            self.Is_begin_weight = False\n","        else:\n","            weight_norm1 = self.relation(self.begin_weight1.t())\n","            weight_norm1 = weight_norm1.t()\n","            weight_norm2 = self.relation(self.begin_weight2.t())\n","            weight_norm2 = weight_norm2.t()\n","\n","        output1 = torch.mm(feat_norm1, torch.t(weight_norm1[:, 0:512])) + weight_norm1[:, 512]\n","        output1 = self.scale * output1 \n","        output2 = torch.mm(feat_norm2, torch.t(weight_norm2[:, 0:512])) + weight_norm2[:, 512]\n","        output2 = self.scale * output2 \n","\n","        if self.fusion_mode == 0 or self.fusion_mode == 1:\n","            temp = torch.cat((feat1, feat2), 1)\n","            output = self.fc(temp)\n","        elif self.fusion_mode == 2:\n","            temp = (feat1 + feat2) / 2\n","            output = self.fc(temp)\n","        elif self.fusion_mode == 3:\n","            temp = torch.cat((feat1, feat2), 1)\n","            output = self.fc(temp)\n","\n","        if self.output == 1:\n","            return weight1, bias1, weight2, bias2, feat1, feat2, output1, output2, output\n","        else: \n","            return output1, output2, output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-uYQfERObaQ","colab_type":"text"},"source":["# Main"]},{"cell_type":"code","metadata":{"id":"MrNx6A8jPcXa","colab_type":"code","colab":{}},"source":["batch_size_num = 64\n","epoch_num = 30 \n","learning_rate = 0.001 \n","weight_decay = 0\n","test_batch_size = 128\n","unlabel_num = 50000\n","\n","########## parameters ############\n","### fusion_mode: 0 no fusion / 1 concate / 2 mean / 3 concate two layer\n","### database: 0 CK+ / 1 BP4D\n","### use_web: 0 only test images/ 1 training with unlabeled images\n","### lambda_co_regularization:\n","### AU_idx: the AU idxes you want to consider\n","fusion_mode = 2\n","database = 0\n","use_web = 1\n","\n","AU_num = 12\n","AU_idx = [0,1,2,3,4,5,6,7,8,9,10,11]\n","\n","lambda_co_regularization = 100 # 100\n","lambda_multi_view = 400\n","\n","########## transforms #############\n","## transform for training\n","transform_train = transforms.Compose([\n","    transforms.Resize(240),\n","    transforms.RandomCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5355, 0.4249, 0.3801), (0.2832, 0.2578, 0.2548)),\n","])\n","\n","## transform for testing\n","transform_test = transforms.Compose([\n","    transforms.Resize(240),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5355, 0.4249, 0.3801), (0.2832, 0.2578, 0.2548)),\n","])\n","\n","def transfrom_img_train(img):\n","    img = transform_train(img)\n","\n","    return img\n","\n","def transfrom_img_test(img):\n","    img = transform_test(img)\n","\n","    return img\n","\n","########## lossfunction ###########\n","# loss function combination all losses, including the L_mv, L_cr and the BCE loss for AU classification\n","# Input: AU_num, AU_idx, fusion_mode, use_web and database are explained in the parameters section\n","\n","# Explaination of the BCE loss: We choose the modified Selective Learning BCE loss for supervision.\n","# Since the positive/negative ratio is very small for some AUs, we only consider the positive under-representation situation\n","# and set a boundary for all AUs.\n","lossfunc = MultiView_all_loss(AU_num = AU_num, AU_idx = AU_idx, fusion_mode = fusion_mode,\n","                use_web = use_web, database = database,\n","                lambda_co_regularization = lambda_co_regularization, lambda_multi_view = lambda_multi_view)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysqPjGBjKIRR","colab_type":"code","colab":{}},"source":["trainset = ImageFolder(\"/content/drive/My Drive/dl_project/ck_dataset/train\", transform_train)\n","testset = ImageFolder(\"/content/drive/My Drive/dl_project/ck_dataset/test\", transform_test)\n","\n","trainloader = DataLoader(trainset, batch_size=batch_size_num, shuffle=True)\n","testloader = DataLoader(testset, batch_size=test_batch_size, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NPWdktapFHvy","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"irq5Gr4uQkHY","colab_type":"code","colab":{}},"source":["net = ResNet_GCN_two_views(AU_num=AU_num, AU_idx=AU_idx, output=1, fusion_mode=fusion_mode, database=database)\n","net.cuda()\n","\n","optimizer = optim.Adam(net.parameters(), lr=0.001) # lr=0.001"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rg0Egn1EQr1a","colab_type":"code","colab":{}},"source":["loss_count = torch.zeros(epoch_num)\n","test_count = torch.zeros(epoch_num)\n","for epoch in range(epoch_num):\n","  sum_loss = 0.0\n","  for i, data in enumerate(trainloader):\n","    img, labels = data\n","    img = img.cuda() # [batch_size, 3, 224, 224]\n","    ground_truth = torch.zeros((len(labels), AU_num)) # [batch_size,12]\n","    for i in range(len(labels)):\n","      ground_truth[i,labels[i]] = 1 # 1 represents the occurrency of the AU\n","\n","    ground_truth = ground_truth.cuda() # [batch_size,12]\n","\n","    weight1, bias1, weight2, bias2, feat1, feat2, output1, output2, output = net(img)\n","\n","    flag = torch.ones((len(labels), AU_num)) # [batch_size,12]\n","    sup_loss, loss_pred, loss_pred1, loss_pred2, loss_multi_view, loss_similar = lossfunc(ground_truth, output, output1, output2, weight1, bias1, weight2, bias2, feat1, feat2, flag)\n","\n","    optimizer.zero_grad()\n","    loss = sup_loss\n","    loss.backward()\n","    optimizer.step()\n","    sum_loss+=loss.item()\n","\n","  loss_count[epoch] = sum_loss\n","  print(\"Epoch %d, loss %4.2f\" % (epoch, sum_loss))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfGEK5bwTwwL","colab_type":"code","colab":{}},"source":["torch.save(net.state_dict(), \"/content/drive/My Drive/dl_project/model/net_epoch30_batch64.weights\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WOcqxhdxSFuh","colab_type":"text"},"source":["### test"]},{"cell_type":"code","metadata":{"id":"xqeiO4HsUGgB","colab_type":"code","outputId":"742205e6-4d9b-4893-c690-b97f917a2fb1","executionInfo":{"status":"ok","timestamp":1590452963092,"user_tz":-60,"elapsed":1802,"user":{"displayName":"DAWEN LIU","photoUrl":"","userId":"09696980981324304683"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["net = ResNet_GCN_two_views(AU_num=AU_num, AU_idx=AU_idx, output=2, fusion_mode=fusion_mode, database=database)\n","model_path = '/content/drive/My Drive/dl_project/model/net_epoch30_batch64.weights'\n","net.load_state_dict(torch.load(model_path))\n","net.cuda()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet_GCN_two_views(\n","  (net1): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","    (fc): Linear(in_features=512, out_features=12, bias=True)\n","  )\n","  (net2): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","    (fc): Linear(in_features=512, out_features=12, bias=True)\n","  )\n","  (fc): Linear(in_features=512, out_features=12, bias=True)\n","  (relation): GCN_layer(\n","    (gc1): GraphConvolution (513 -> 513)\n","    (gc2): GraphConvolution (513 -> 513)\n","    (relu): LeakyReLU(negative_slope=0.2)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"VVzDdnVPSFW7","colab_type":"code","colab":{}},"source":["count = 0\n","f1_score_count = np.zeros(len(testloader))\n","with torch.no_grad():\n","  for i, data in enumerate(testloader):\n","    img, labels = data\n","\n","    img = img.cuda()\n","    labels = labels.cuda()\n","\n","    AU_view1, AU_view2, AU_fusion = net(img)\n","    # AU_view1 = torch.sigmoid(AU_view1)\n","    # AU_view2 = torch.sigmoid(AU_view2)\n","    AU_fusion = torch.sigmoid(AU_fusion)\n","    AU_pred = torch.argmax(AU_fusion,axis=1)\n","    count += torch.eq(AU_pred, labels).sum().item()\n","\n","    #F1 score\n","    # p = precision_score(y_true, y_pred, average='binary')\n","    # r = recall_score(y_true, y_pred, average='binary')\n","    f1_score_count[i] = f1_score(labels.data.cpu().numpy(), AU_pred.data.cpu().numpy(), average='micro')\n","\n","accuracy = count / len(testset) * 100\n","print(\"accuracy on test set:\",accuracy)\n","print(\"average F1 score over 12 AUs\", np.mean(f1_score_count))"],"execution_count":0,"outputs":[]}]}